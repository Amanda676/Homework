{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enabling-ethernet",
   "metadata": {},
   "source": [
    "# Week 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-feature",
   "metadata": {},
   "source": [
    "### 1.\tPerform combined over and undersampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frequent-purse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "diabetes_df = pd.read_csv(\"Classwork/diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eleven-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "increased-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop('Outcome',axis = 1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "#Standardize\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-treaty",
   "metadata": {},
   "source": [
    "### Logistic Regression using SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collectible-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTEENN(random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "difficult-worst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train using the resampled data\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geographic-theater",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7088888888888889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "# old resampling comment below\n",
    "#increased accuracy from .6 to .74 by using oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intermediate-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thrown-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64 36]\n",
      " [12 42]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "racial-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.64      0.73       100\n",
      "           1       0.54      0.78      0.64        54\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.69      0.71      0.68       154\n",
      "weighted avg       0.74      0.69      0.70       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-mining",
   "metadata": {},
   "source": [
    "**SMOTEEN** Combined over and under sampling\n",
    "\n",
    "SMOTEEN uses SMOTE and ENN to create more samples in the majority and minority classes.  SMOTE create new minority data points using original minority data points to better represent the minority class. It doesn't repeat the same minoirty data points as naive oversampling.\n",
    "\n",
    "ENN (Edited Nearest Neighbors).  From what I've read, it seems to locate misclassified data points and removed them using nearest neighbors.  By default, ENN removes data from both minority and majority classes.   So if the observation is in disagreement over the k(default=3) nearest neighbors majority class, then all are deleted.\n",
    "\n",
    "I ran the default method above.  It's possible that tuning the SMOTEEN would product better results in the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-hygiene",
   "metadata": {},
   "source": [
    "### Decision Tree Regression using SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "configured-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = tree.DecisionTreeClassifier(max_depth=6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "awful-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = tree_model.fit(X_res, y_res)\n",
    "y_tree_pred = tree_model.predict(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "meaning-trustee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64, 36],\n",
       "       [10, 44]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "respective-burns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.74       100\n",
      "           1       0.55      0.81      0.66        54\n",
      "\n",
      "    accuracy                           0.70       154\n",
      "   macro avg       0.71      0.73      0.70       154\n",
      "weighted avg       0.75      0.70      0.71       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "municipal-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7274074074074074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_tree_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-sucking",
   "metadata": {},
   "source": [
    "### Decision Tree Regression using SMOTEEN, taking out BloodPressure and SkinThickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attempted-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_2 = tree.DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "\n",
    "X = diabetes_df.drop(['Outcome', 'BloodPressure', 'SkinThickness'], axis = 1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "#Standardize\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "oriental-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTEENN(random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "necessary-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_2.fit(X_res, y_res)\n",
    "y_tree_pred2 = tree_model_2.predict(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "entertaining-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73, 27],\n",
       "       [15, 39]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_tree_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "organized-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78       100\n",
      "           1       0.59      0.72      0.65        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.73      0.71       154\n",
      "weighted avg       0.75      0.73      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_tree_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "honest-cannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261111111111112"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_tree_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-animation",
   "metadata": {},
   "source": [
    "### 2.\tComment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-cincinnati",
   "metadata": {},
   "source": [
    "The performance improved for False Negative class, but I'm not sure there are huge gains.\n",
    "\n",
    "In tyring to directly compare models, I've chosed balanced accuracy score.  However, I think there are many other ways to think about performance.   We can look at the precision for all models, computational time, and perhaps, more importantly, the false negative rate.\n",
    "\n",
    "With recall = TP/(TP + FN), as False Negatives are smaller, the recall rate moves closer to 1.\n",
    "\n",
    "So another way to score the diabetes models would be to look at the recall of class 1.  In the SMOTE and SMOTEEN resampling, the recall of class 1 improved.  This number was in the mid-50s and moved to 70s and above.\n",
    "\n",
    "Other sampling techiniques (lecture notebook) seem to help improve the recall of class 1.  However those used imbalanced classification report and I don't know if there is a direct comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-authority",
   "metadata": {},
   "source": [
    "Using balanced_accuracy_score (average of recall obtained on each class):\n",
    "\n",
    "73% accuracy score from SMOTE using LogisticRegression (Source: Week_15_inclass)\n",
    "\n",
    "71% accuracy score from SMOTEEN using LogisticRegression.  (Source: this notebook)\n",
    "\n",
    "73% accuracy score from SMOTEEN using DecisionTreeRegression (Source: this notebook)\n",
    "\n",
    "77% accuracy score using DecisionTreeRegression when BloodPressue and SkinThickness were taken out. (Source: Week_16_Group_inClass)\n",
    "\n",
    "71% accuracy score from LogisticRegression (Source: Week_14_homework)\n",
    "\n",
    "73% accuracy score from LogisticRegression when BloodPressue and SkinThickness were taken out (Source: Week_14_homework)\n",
    "\n",
    "68% accuracy score from KNN (Source: Week_14_homework) This is different than the model score of 72%\n",
    "\n",
    "74% accuracy score from RandomOverSampler and Logistic Regression. (Source: over_under_sampling.ipynb class notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-testament",
   "metadata": {},
   "source": [
    "After looking at all these accuracy numbers, I tried to improve the performance of the SMOTEEN using DecisionTreeRegression by taking out BloodPressure and SkinThickness.   I ran few different max_depth trees, but did not get a radical performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-application",
   "metadata": {},
   "source": [
    "### 3.\tWhat is outlier detection? Why is it useful? What methods can you use for outlier detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-fossil",
   "metadata": {},
   "source": [
    "Outlier detection looks for data points that can lie far out of the distribution of the data points.  For example, data that lies 2-3 standard deviations from the mean for a normal distribution would be considered outliers.\n",
    "\n",
    "Outliers could be noise, data errors, experimental errors, naturally occurring, or even experiements themselves (how does the model handle the outier).  In some cases, the model itself is trying to detect outliers.   Even in the diabetes data set, diabetes itself is an outlier, so a diabetes detection model is trying to predict the outliers.\n",
    "\n",
    "Methods:\n",
    "* Using standard deviation\n",
    "* A mulitiplier (like 1.5) outside the interquartile ranges\n",
    "* DBScan Clustering or other clustering algorithms\n",
    "* Isolation Forest\n",
    "* Robust Random Cut Forest\n",
    "* Z-Score (based on std dev)\n",
    "* Linear Regression Models (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-suggestion",
   "metadata": {},
   "source": [
    "### 4.\tPerform a linear SVM to predict credit approval (last column) using this dataset: \n",
    "https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29 . Make sure you look at the accompanying document that describes the data in the dat file. You will need to either convert this data to another file type or import the dat file to python. \n",
    "You can use this code, but otherwise you follow standard practices we have already used many times: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "needed-antique",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2   3   4   5      6   7   8   9   10  11   12    13  14\n",
       "0   1  22.08  11.46   2   4   4  1.585   0   0   0   1   2  100  1213   0\n",
       "1   0  22.67   7.00   2   8   4  0.165   0   0   0   0   2  160     1   0\n",
       "2   0  29.58   1.75   1   4   4  1.250   0   0   0   1   2  280     1   0\n",
       "3   0  21.67  11.50   1   5   3  0.000   1   1  11   1   2    0     1   1\n",
       "4   1  20.17   8.17   2   6   4  1.960   1   1  14   0   2   60   159   1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df = pd.read_table(\"australian.dat\", sep=\" \",header=None)\n",
    "credit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "voluntary-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    int64  \n",
      " 1   1       690 non-null    float64\n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    int64  \n",
      " 4   4       690 non-null    int64  \n",
      " 5   5       690 non-null    int64  \n",
      " 6   6       690 non-null    float64\n",
      " 7   7       690 non-null    int64  \n",
      " 8   8       690 non-null    int64  \n",
      " 9   9       690 non-null    int64  \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    int64  \n",
      " 12  12      690 non-null    int64  \n",
      " 13  13      690 non-null    int64  \n",
      " 14  14      690 non-null    int64  \n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 81.0 KB\n"
     ]
    }
   ],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceramic-reflection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.678261</td>\n",
       "      <td>31.568203</td>\n",
       "      <td>4.758725</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>7.372464</td>\n",
       "      <td>4.692754</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>0.523188</td>\n",
       "      <td>0.427536</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>0.457971</td>\n",
       "      <td>1.928986</td>\n",
       "      <td>184.014493</td>\n",
       "      <td>1018.385507</td>\n",
       "      <td>0.444928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.467482</td>\n",
       "      <td>11.853273</td>\n",
       "      <td>4.978163</td>\n",
       "      <td>0.430063</td>\n",
       "      <td>3.683265</td>\n",
       "      <td>1.992316</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>0.499824</td>\n",
       "      <td>0.495080</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>0.498592</td>\n",
       "      <td>0.298813</td>\n",
       "      <td>172.159274</td>\n",
       "      <td>5210.102598</td>\n",
       "      <td>0.497318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.625000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.707500</td>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>396.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  690.000000  690.000000  690.000000  690.000000  690.000000  690.000000   \n",
       "mean     0.678261   31.568203    4.758725    1.766667    7.372464    4.692754   \n",
       "std      0.467482   11.853273    4.978163    0.430063    3.683265    1.992316   \n",
       "min      0.000000   13.750000    0.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000   22.670000    1.000000    2.000000    4.000000    4.000000   \n",
       "50%      1.000000   28.625000    2.750000    2.000000    8.000000    4.000000   \n",
       "75%      1.000000   37.707500    7.207500    2.000000   10.000000    5.000000   \n",
       "max      1.000000   80.250000   28.000000    3.000000   14.000000    9.000000   \n",
       "\n",
       "               6           7           8          9           10          11  \\\n",
       "count  690.000000  690.000000  690.000000  690.00000  690.000000  690.000000   \n",
       "mean     2.223406    0.523188    0.427536    2.40000    0.457971    1.928986   \n",
       "std      3.346513    0.499824    0.495080    4.86294    0.498592    0.298813   \n",
       "min      0.000000    0.000000    0.000000    0.00000    0.000000    1.000000   \n",
       "25%      0.165000    0.000000    0.000000    0.00000    0.000000    2.000000   \n",
       "50%      1.000000    1.000000    0.000000    0.00000    0.000000    2.000000   \n",
       "75%      2.625000    1.000000    1.000000    3.00000    1.000000    2.000000   \n",
       "max     28.500000    1.000000    1.000000   67.00000    1.000000    3.000000   \n",
       "\n",
       "                12             13          14  \n",
       "count   690.000000     690.000000  690.000000  \n",
       "mean    184.014493    1018.385507    0.444928  \n",
       "std     172.159274    5210.102598    0.497318  \n",
       "min       0.000000       1.000000    0.000000  \n",
       "25%      80.000000       1.000000    0.000000  \n",
       "50%     160.000000       6.000000    0.000000  \n",
       "75%     272.000000     396.500000    1.000000  \n",
       "max    2000.000000  100001.000000    1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mineral-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at the distributions of the column data\n",
    "credit_df.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "usual-romania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "685    1\n",
       "686    0\n",
       "687    1\n",
       "688    1\n",
       "689    1\n",
       "Name: 14, Length: 690, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing calling column - first time we've worked in an int named column instead of a string\n",
    "credit_df[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "statutory-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from problem set\n",
    "from sklearn.svm import SVC\n",
    "lsvc_model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "decent-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test, 25% test data\n",
    "# stratify on y, because outcome class is not quite 50/50\n",
    "X = credit_df.drop(14, axis = 1)\n",
    "y = credit_df[14]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "variable-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "electronic-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_model.fit(X_train_scaler, y_train)\n",
    "\n",
    "lsvc_y_pred = lsvc_model.predict(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "universal-density",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69, 27],\n",
       "       [ 6, 71]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, lsvc_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "numeric-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81        96\n",
      "           1       0.72      0.92      0.81        77\n",
      "\n",
      "    accuracy                           0.81       173\n",
      "   macro avg       0.82      0.82      0.81       173\n",
      "weighted avg       0.83      0.81      0.81       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lsvc_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "italian-dairy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72, 24],\n",
       "       [ 8, 69]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I also tried running the SVC on non-scaled data.   Probably NOT the right thing to do.\n",
    "# Further reading says SVC-linear works best on scaled data.\n",
    "# This unscaled data model also seems to take longer to run\n",
    "new_model = SVC(kernel='linear')\n",
    "new_model.fit(X_train, y_train)\n",
    "lsvc_y_pred_unscaled = new_model.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, lsvc_y_pred_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "virgin-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        96\n",
      "           1       0.74      0.90      0.81        77\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.82      0.82      0.81       173\n",
      "weighted avg       0.83      0.82      0.82       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unscaled data\n",
    "print(classification_report(y_test, lsvc_y_pred_unscaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-terrorism",
   "metadata": {},
   "source": [
    "### 5.\tHow did the SVM model perform? Use a classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "motivated-little",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81        96\n",
      "           1       0.72      0.92      0.81        77\n",
      "\n",
      "    accuracy                           0.81       173\n",
      "   macro avg       0.82      0.82      0.81       173\n",
      "weighted avg       0.83      0.81      0.81       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this model used the scaled data\n",
    "print(classification_report(y_test, lsvc_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-village",
   "metadata": {},
   "source": [
    "**The SVM model preformed well.**\n",
    "\n",
    "The precision for class 1 is 72% - not great accuracy, but not bad.\n",
    "The recall for 1 is 90%, so the model predicted 90% of class 1.\n",
    "\n",
    "The precision for class 0 is 92% - high accuracy for this class.\n",
    "The recall for 0 is 72%, so the model predicited 72% of class 0.\n",
    "\n",
    "Depending on what class 1 and 0 are, this model could be ideal if the answer has to do with credit worthiness.  However if the false positive number (27 from the confusion matrix) was those that model deemed credit worthy (for example), but were not, that's really concerning.  Unlike the diabetes data set, the business would rather have a low false positive rate than a low false negative rate if what we're talking about is credit worthiness. It would be easier to review by human false negative data then auto approve the false positives (seemed credit worthy, but were not).  \n",
    "\n",
    "\n",
    "***IF THE MODEL INDICATES CREDIT APPROVAL WITH CLASS 1:***\n",
    "\n",
    "Then the model should only be used to automatically deny credit approval, but not *approve* credit.  Clearly, it seems risky that the precision for Class 1 is so low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-davis",
   "metadata": {},
   "source": [
    "### 6.\tWhat kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-formation",
   "metadata": {},
   "source": [
    "I am most interested in **applying data to solve business or industry problems or using data to provide insight**.  Being part of team with individual and group work sounds most appealing with opportunities to grow my technical skills.  Most jobs seem to be titled as a data analyst or associate data scientist.\n",
    "\n",
    "One job that sounds that I would meet the qualifications for is a **Data Reporting Specialist** with Anheuser-Busch.   The job description part that interests me the most are **sales modeling** for near- and long-term projections, **programming ability, willingness to learn new skills, team-orientation**, and **ability to draw insightful conclusions and communicate them**.\n",
    "\n",
    "Another job description I liked was a **python and SQL developer** where the job requirement was to develop a new security tool that will help protect and match large sets of data.\n",
    "\n",
    "A few of the jobs that are interesting to me also have requirements for MS or PhD in a technical field such as computer science or mathematics.  \n",
    "\n",
    "The **Associate Data Scientist** with Spectrum Brands job description would be something I’m interested in.   The job **supports sales, marketing, supply chain and leadership teams** with insights derived from analyzing internal and external data. One responsibility is developing **custom data models and algorithms** to apply to data sets and predictive modeling.  **Communicating to non-technical audiences** is also required and something I like to do.\n",
    "\n",
    "**I like to head up projects and using soft skills to build collaboration.**  At this time, I’m not interested in managing a team or group; I would rather be a contributing team member.  \n",
    "\n",
    "Being a beginner at data analytics and data science, having no team support or mentor to learn from is probably my largest concern.  Also, the more I am learning through class, the more I know I don’t know and that motivates me to keep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-custom",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
